{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac7ace8d-2d2b-4a4d-af44-0beed954624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "DTYPE = np.float64\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.insert(0, \"../../packages\")\n",
    "import flory_\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2263bb-a304-4ecb-b172-a37accadcd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flory Huggins Free Energy function\n",
    "def floryHuggins(phi:DTYPE, chi:np.array):\n",
    "    part_1 = np.sum(phi*np.log(phi))\n",
    "    part_2 = 0\n",
    "\n",
    "    for i in range(len(phi)):\n",
    "        for j in range(i+1, len(phi)):\n",
    "            part_2 += chi[i][j]*phi[i]*phi[j]\n",
    "\n",
    "    return part_1 + part_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddd64f9-77d0-4e7a-ba0c-ffec17e32521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Function for computing mergers of compartments\n",
    "# Returns the concentrations of components in the merged and the unmerged compartments\n",
    "# Stores them in phi_in_kmerged and phi_in_kunmerged respectively.\n",
    "\n",
    "\n",
    "def mergers(concs:np.array, vols:np.array, chis, merged_compartments:list):\n",
    "    # Find the unmerged compartment(s)\n",
    "    expected = len(vols)*(len(vols)+1)//2\n",
    "    actual = np.sum(merged_compartments)\n",
    "    unmerged_compartment = expected - actual\n",
    "\n",
    "    # print(concs)\n",
    "    # print(vols)\n",
    "    # print(unmerged)\n",
    "\n",
    "    # Compute the merged volumes, stored in variable eta_merged\n",
    "    # subtract -1 from the merged_compartments idxs to maintain python idxing\n",
    "    eta_merged = 0\n",
    "    for compartment in merged_compartments:\n",
    "        eta_merged += vols[compartment-1]\n",
    "    # print(eta_merged)\n",
    "\n",
    "    # Calculating the compositions of components in the merged compartment\n",
    "    # Taking a simple weighted average\n",
    "    phi_1merged = (vols[merged_compartments[0]-1]*concs[0, merged_compartments[0]-1] + vols[merged_compartments[1]-1]*concs[0, merged_compartments[1]-1])/eta_merged\n",
    "    phi_2merged = (vols[merged_compartments[0]-1]*concs[1, merged_compartments[0]-1] + vols[merged_compartments[1]-1]*concs[1, merged_compartments[1]-1])/eta_merged\n",
    "    phi_3merged = 1 - phi_1merged - phi_2merged\n",
    "    # print(phi_1merged, phi_2merged, phi_3merged)\n",
    "    # print(phi_1merged + phi_2merged + phi_3merged)\n",
    "\n",
    "    phi_in_kmerged = [phi_1merged, phi_2merged, phi_3merged]\n",
    "    phi_in_kunmerged = [concs[0, unmerged_compartment-1], concs[1, unmerged_compartment-1], concs[2, unmerged_compartment-1]]\n",
    "    # print(phi_in_kmerged)\n",
    "    # print(phi_in_kunmerged)\n",
    "\n",
    "    F_merged = eta_merged*floryHuggins(phi_in_kmerged, chis) + vols[unmerged_compartment-1]*floryHuggins(phi_in_kunmerged, chis)\n",
    "    # print(F_merged)\n",
    "\n",
    "    return phi_in_kunmerged, phi_in_kmerged, eta_merged, unmerged_compartment\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7df1041-00e7-4ce8-8f96-c7df4b52a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global concentrations\n",
    "phi_globals = [\n",
    "                # np.array([0.1, 0.4, 0.5], dtype=DTYPE),\n",
    "                # np.array([0.1, 0.5, 0.4], dtype=DTYPE),\n",
    "                # np.array([0.4, 0.1, 0.5], dtype=DTYPE),\n",
    "                # np.array([0.4, 0.5, 0.1], dtype=DTYPE),\n",
    "                # np.array([0.5, 0.1, 0.4], dtype=DTYPE),\n",
    "                # np.array([0.5, 0.4, 0.1], dtype=DTYPE),\n",
    "                # np.array([0.2, 0.3, 0.5], dtype=DTYPE),\n",
    "                # np.array([0.2, 0.5, 0.3], dtype=DTYPE),\n",
    "                # np.array([0.3, 0.2, 0.5], dtype=DTYPE),\n",
    "                # np.array([0.3, 0.5, 0.2], dtype=DTYPE),\n",
    "                # np.array([0.5, 0.2, 0.3], dtype=DTYPE),\n",
    "                # np.array([0.5, 0.3, 0.2], dtype=DTYPE),\n",
    "                # np.array([0.2, 0.2, 0.6], dtype=DTYPE),\n",
    "                # np.array([0.2, 0.6, 0.2], dtype=DTYPE),\n",
    "                # np.array([0.6, 0.2, 0.2], dtype=DTYPE),\n",
    "                # np.array([0.4, 0.3, 0.3], dtype=DTYPE),\n",
    "                # np.array([0.3, 0.4, 0.3], dtype=DTYPE),\n",
    "                # np.array([0.3, 0.3, 0.4], dtype=DTYPE),\n",
    "                np.array([0.1, 0.7, 0.2], dtype=DTYPE)\n",
    "]\n",
    "\n",
    "Xs = np.arange(0, 10.1, 0.1)\n",
    "\n",
    "N_STEPS = [1000000]\n",
    "# Xs = [0]\n",
    "# tol = DTYPE(1e-4)\n",
    "# x = 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01823a96-c26e-46f3-b17d-6bf4e9d06bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.7 0.2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 101/101 [00:58<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for phi_global in (phi_globals):\n",
    "    print(phi_global)\n",
    "    for X in tqdm(Xs):\n",
    "        for steps in N_STEPS:\n",
    "    \n",
    "            chis = np.array([[0, 3.0, 3+X], [3.0, 0.0, 3.0], [3+X, 3.0, 0.0]], dtype = DTYPE)\n",
    "        \n",
    "            #################################\n",
    "            # Run Flory for the first time\n",
    "            # To get at most n_components distinct phases\n",
    "            #################################\n",
    "        \n",
    "            n_components = 3\n",
    "            free_energy = flory_.free_energy.FloryHuggins(n_components, chis)\n",
    "            interaction = free_energy.interaction\n",
    "            entropy = free_energy.entropy\n",
    "            ensemble = flory_.CanonicalEnsemble(n_components, phi_global)\n",
    "            options = {\"num_part\": 32, \"progress\": False, \"max_steps\": 100000}\n",
    "            \n",
    "            finder = flory_.CoexistingPhasesFinder(interaction, entropy, ensemble, **options)\n",
    "            phases = finder.run(progress=False)\n",
    "        \n",
    "            # Get the number of phases\n",
    "            vols = phases.get_clusters().volumes\n",
    "            concs = phases.get_clusters().fractions\n",
    "            \n",
    "            # Normalize volumes\n",
    "            vols = vols/np.sum(vols)\n",
    "            # vols, concs\n",
    "        \n",
    "            output_filepath = f\"data/withFlory/phi_g{phi_global}/raw/X{X:.3f}/\"\n",
    "            output_filename = f\"initial_system.pkl\"\n",
    "            if not os.path.exists(output_filepath):\n",
    "                os.makedirs(output_filepath)\n",
    "            output_file = os.path.join(output_filepath, output_filename)\n",
    "            data_to_save = {\n",
    "                \"chis\": chis,\n",
    "                \"phi_global\": phi_global,\n",
    "                \"flory_phases\": concs,\n",
    "                \"flory_vols\": vols,\n",
    "                \"metadata\": {\"chis-> chi matrix\", \"phi_global-> system global concentrations\", \"flory_phases-> flory's concentration output for distinct 3 phase solution\", \"flory_vols-> flory's output for corresponding phase vols\"}\n",
    "            }\n",
    "            with gzip.open(output_file, \"wb\") as f:\n",
    "                pickle.dump(data_to_save, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "            ################################\n",
    "            # Now, merge Compartments\n",
    "            ################################\n",
    "            merged_compartments_list = [np.array([1, 2], dtype=np.int64), np.array([1, 3], dtype=np.int64), np.array([2, 3], dtype=np.int64)]\n",
    "            \n",
    "            for merged_compartments in (merged_compartments_list):\n",
    "                if concs.shape[0] == 3: # force 3 phase, else skip                    \n",
    "                    phi_in_kunmerged, phi_in_kmerged, eta_merged, unmerged_compartment = mergers(concs, vols, chis, merged_compartments)\n",
    "                    # print(unmerged_compartment)\n",
    "                    f_initial = eta_merged*floryHuggins(phi_in_kmerged, chis) + (1-eta_merged)*floryHuggins(phi_in_kunmerged, chis)\n",
    "                    # print(f_initial)\n",
    "                    \n",
    "                    phi_global_ = np.array([phi_in_kmerged, phi_in_kunmerged])\n",
    "                    vols_ = np.array([eta_merged, 1-eta_merged])\n",
    "                    \n",
    "                    options = {\n",
    "                    \"num_part\": 2,\n",
    "                    \"progress\": False,\n",
    "                    \"max_steps\": steps,  # disable progress bar, allow more steps\n",
    "                    }\n",
    "                    \n",
    "                    finder2 = flory_.CoexistingPhasesFinder(interaction, entropy, ensemble, **options)\n",
    "                    # finder2.reinitialize_from_omegas(-np.log(np.transpose(phi_global_)), vols_)\n",
    "                    finder2.reinitialize_from_phis(np.transpose(phi_global_), vols_)\n",
    "                    phases = finder2.run(progress=False).get_clusters()\n",
    "                \n",
    "                    vols_m =  phases.volumes/np.sum(phases.volumes)\n",
    "                    fracs_m = phases.fractions\n",
    "                \n",
    "                    f = []\n",
    "                    for idx, _ in enumerate(vols_m):\n",
    "                        f.append(vols_m[idx]*floryHuggins(fracs_m[idx], chis))\n",
    "                    f_best = np.sum(f)\n",
    "                    \n",
    "                    output_filepath = f\"data/withFlory/phi_g{phi_global}/raw/X{X:.3f}/steps{steps}/mergers/{merged_compartments}/\"\n",
    "                    output_filename = f\"initial_and_best.pkl\"\n",
    "                    if not os.path.exists(output_filepath):\n",
    "                        os.makedirs(output_filepath)\n",
    "                    output_file = os.path.join(output_filepath, output_filename)\n",
    "                    data_to_save = {\n",
    "                        \"merged_compartments\": merged_compartments,\n",
    "                        \"initial_guess\": [phi_global_, vols_],\n",
    "                        \"F_initial\": f_initial,\n",
    "                        \"best_location\": [fracs_m, vols_m],\n",
    "                        \"F_best\": f_best,\n",
    "                        \"metadata\": {\n",
    "                            \"initial_guess\": \"stores the initial merged guesses [phi_merged, eta_merged]\",\n",
    "                            \"F_initial\": \"stores the initial free energy for the guess\",\n",
    "                            \"best_location\": \"stores flory's output for the local minima positions [phi_flory, eta_flory] -> takes the first row of the phi matrix and the first entry of the volume array\",\n",
    "                            \"F_best\": \"stores the best free energy\"\n",
    "                        }\n",
    "                    }\n",
    "            \n",
    "                    # print(data_to_save)\n",
    "                    with gzip.open(output_file, \"wb\") as file:\n",
    "                        pickle.dump(data_to_save, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                    # with gzip.open(output_file, 'rb') as f:\n",
    "                    #     loaded_data = pickle.load(f)\n",
    "                    # print(loaded_data)\n",
    "                    # print(f_best)\n",
    "            \n",
    "                    # print(f\"merged compartments {merged_compartments}\")\n",
    "                    # print(f\"p_merged {phi_in_kmerged}\")\n",
    "                    # print(f\"eta_merged {eta_merged}\")\n",
    "                    # print(f\"vols {vols_m}\")\n",
    "                    # print(f\"fracs {fracs_m}\")\n",
    "                    # print(f\"F {f_tot}\")\n",
    "                    # print()\n",
    "                \n",
    "                else:\n",
    "                    print(f\"Skipped for X {X}, Steps {steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f223fb-aa07-4fc8-b41a-9bde4e8c695c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1d32a-a61d-4c05-a57d-5b01f8e144b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbc8708-cd78-4bac-ab29-393789e1e2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff2cf03-e7ae-4566-ba5d-6372f8de4156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab9f9ec-ee3e-4d6f-8ca5-0a8543efa279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb695b6-e5bf-460d-a4f7-bf63134b109d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
