{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd70aac-be7e-4989-aa88-2c673ae2aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "DTYPE = np.float64\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "# try:\n",
    "#     import flory\n",
    "    \n",
    "# except ImportError:\n",
    "#     print(\"Installing 'flory' temporarily...\")\n",
    "#     !pip install flory --quiet\n",
    "#     import flory\n",
    "\n",
    "# from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca732f4-4ce8-465d-8016-a0d86e0f2e1f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# General Function for computing mergers of compartments\n",
    "# Returns the concentrations of components in the merged and the unmerged compartments\n",
    "# Stores them in phi_in_kmerged and phi_in_kunmerged respectively.\n",
    "\n",
    "\n",
    "def mergers(concs:np.array, vols:np.array, chis, merged_compartments:list):\n",
    "    # Find the unmerged compartment(s)\n",
    "    expected = len(vols)*(len(vols)+1)//2\n",
    "    actual = np.sum(merged_compartments)\n",
    "    unmerged_compartment = expected - actual\n",
    "\n",
    "    # print(concs)\n",
    "    # print(vols)\n",
    "    # print(unmerged)\n",
    "\n",
    "    # Compute the merged volumes, stored in variable eta_merged\n",
    "    # subtract -1 from the merged_compartments idxs to maintain python idxing\n",
    "    eta_merged = 0\n",
    "    for compartment in merged_compartments:\n",
    "        eta_merged += vols[compartment-1]\n",
    "    # print(eta_merged)\n",
    "\n",
    "    # Calculating the compositions of components in the merged compartment\n",
    "    # Taking a simple weighted average\n",
    "    phi_1merged = (vols[merged_compartments[0]-1]*concs[0, merged_compartments[0]-1] + vols[merged_compartments[1]-1]*concs[0, merged_compartments[1]-1])/eta_merged\n",
    "    phi_2merged = (vols[merged_compartments[0]-1]*concs[1, merged_compartments[0]-1] + vols[merged_compartments[1]-1]*concs[1, merged_compartments[1]-1])/eta_merged\n",
    "    phi_3merged = 1 - phi_1merged - phi_2merged\n",
    "    # print(phi_1merged, phi_2merged, phi_3merged)\n",
    "    # print(phi_1merged + phi_2merged + phi_3merged)\n",
    "\n",
    "    phi_in_kmerged = [phi_1merged, phi_2merged, phi_3merged]\n",
    "    phi_in_kunmerged = [concs[0, unmerged_compartment-1], concs[1, unmerged_compartment-1], concs[2, unmerged_compartment-1]]\n",
    "    # print(phi_in_kmerged)\n",
    "    # print(phi_in_kunmerged)\n",
    "\n",
    "    F_merged = eta_merged*floryHuggins(phi_in_kmerged, chis) + vols[unmerged_compartment-1]*floryHuggins(phi_in_kunmerged, chis)\n",
    "    # print(F_merged)\n",
    "\n",
    "    return phi_in_kunmerged, phi_in_kmerged, eta_merged, unmerged_compartment\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e6c0b4-eaa8-48e2-a120-d4a39e3c2d4b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Flory Huggins Free Energy function\n",
    "def floryHuggins(phi:DTYPE, chi:np.array):\n",
    "    part_1 = np.sum(phi*np.log(phi))\n",
    "    part_2 = 0\n",
    "\n",
    "    for i in range(len(phi)):\n",
    "        for j in range(i+1, len(phi)):\n",
    "            part_2 += chi[i][j]*phi[i]*phi[j]\n",
    "\n",
    "    return part_1 + part_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb98e15a-2385-4feb-a1d7-ea55b7292c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_global = np.array([0.2, 0.2, 0.6], dtype = DTYPE)\n",
    "Xs = np.arange(0, 10.1, 0.1)\n",
    "tol = DTYPE(1e-4)\n",
    "step_size = 0.001\n",
    "n_points = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7cd2de3-673c-4425-b179-911cba19a769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the Best Merger in 2 steps:\n",
    "# 1. Find the best volume slice for a specific merger from [12] [23] [13]\n",
    "# 2. Then Find the best merger from these best volume slices\n",
    "\n",
    "# I did them seprately for my convenience to debug\n",
    "\n",
    "# Step 1\n",
    "for X in (Xs):\n",
    "\n",
    "    # Load the Flory's files to get the initial guesses to construct the perturbed state\n",
    "    input_filepath = f\"../../../../../../../../media/vchirag24/Shared Drive/Chirag/3_comp_3_phase/data/withVolFluctuations/phi_g{phi_global}/raw/X{X:.3f}/\"\n",
    "    input_filename = f\"FLORY_3phase_solution.pkl\"\n",
    "    input_file = os.path.join(input_filepath, input_filename)\n",
    "    \n",
    "    with gzip.open(input_file, 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "\n",
    "    concs = loaded_data[\"phase_fractions\"]\n",
    "    vols = loaded_data[\"phase_volumes\"]\n",
    "    chis = loaded_data[\"chis\"]\n",
    "\n",
    "    merged_compartments_list = [np.array([1, 2], dtype=np.int64), np.array([2, 3], dtype=np.int64), np.array([1, 3], dtype=np.int64)]\n",
    "    # merged_compartments_list = [np.array([1, 2], dtype=np.int64)]\n",
    "    \n",
    "    for idx, merged_compartments in enumerate(merged_compartments_list):\n",
    "        phi_in_kunmerged, phi_in_kmerged, eta_merged, unmerged_compartment = mergers(concs, vols, chis, merged_compartments)\n",
    "        \n",
    "        eta_merged_perturbed = np.linspace(max(tol, eta_merged - n_points*step_size), min(1-tol, eta_merged + n_points*step_size), 2*n_points+1)\n",
    "\n",
    "        # Find the best volume slice for a particular merger\n",
    "        min_F_best_slice = DTYPE(np.inf)\n",
    "        best_slice = None\n",
    "\n",
    "        for eta_m in eta_merged_perturbed:\n",
    "            input_filepath = f\"../../../../../../../../media/vchirag24/Shared Drive/Chirag/3_comp_3_phase/data/withVolFluctuations/phi_g{phi_global}/raw/X{X:.3f}/mergers/{merged_compartments}/volume_slices/\"\n",
    "            input_filename = f\"eta_m{eta_m:.3f}.pkl\"\n",
    "            input_file = os.path.join(input_filepath, input_filename)\n",
    "            \n",
    "            with gzip.open(input_file, \"rb\") as f:\n",
    "                loaded_data = pickle.load(f)\n",
    "\n",
    "            if len(loaded_data[\"F\"]) > 0:\n",
    "                min_F_slice = np.min(loaded_data[\"F\"]) # minimum F in this slice\n",
    "            else:\n",
    "                min_F_slice = None # minimum F in this slice\n",
    "            # min_F_slice = np.min(loaded_data[\"F\"]) # minimum F in this slice\n",
    "            # print(np.min(loaded_data[\"F\"]))\n",
    "\n",
    "            if min_F_slice is not None and (min_F_best_slice is None or min_F_slice < min_F_best_slice):\n",
    "                min_F_best_slice = min_F_slice\n",
    "                best_slice = eta_m\n",
    "            # if min_F_slice < min_F_best_slice:\n",
    "            #     min_F_best_slice = min_F_slice\n",
    "            #     best_slice = eta_m\n",
    "        \n",
    "        # For every merger, write the best slice to a .pkl file\n",
    "        output_filepath = f\"../../../../../../../../media/vchirag24/Shared Drive/Chirag/3_comp_3_phase/data/withVolFluctuations/phi_g{phi_global}/analysis/X{X:.3f}/mergers/{merged_compartments}/best_volume_slice/\"\n",
    "        output_filename = f\"best_slice.pkl\"\n",
    "        if not os.path.exists(output_filepath):\n",
    "            os.makedirs(output_filepath)\n",
    "        output_file = os.path.join(output_filepath, output_filename)\n",
    "        \n",
    "        data_to_save = {\n",
    "            \"best_slice\": best_slice,\n",
    "            \"min_F\": min_F_best_slice,\n",
    "            \"metadata\": {\"best_slice-> stores the slice per merger which returns locally the lowest free energy\", \n",
    "                         \"min_F-> stores the correesponding minimum F for this slice \"}\n",
    "            }\n",
    "        \n",
    "        with gzip.open(output_file, \"wb\") as f:\n",
    "            pickle.dump(data_to_save, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        # print(output_file, best_slice)\n",
    "        # print()\n",
    "        # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af6799f2-ab62-440e-8fe4-29d2ae4dce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "# Find the best merger\n",
    "for X in (Xs):\n",
    "    merged_compartments_list = [np.array([1, 2], dtype=np.int64), np.array([2, 3], dtype=np.int64), np.array([1, 3], dtype=np.int64)]\n",
    "    # merged_compartments_list = [np.array([1, 2], dtype=np.int64)]\n",
    "\n",
    "    min_F_best = DTYPE(np.inf)\n",
    "    best_merger_slice = None\n",
    "    best_merger_compartment = None\n",
    "    for idx, merged_compartments in enumerate(merged_compartments_list):\n",
    "        # Get the best slice for each merger\n",
    "        input_filepath = f\"../../../../../../../../media/vchirag24/Shared Drive/Chirag/3_comp_3_phase/data/withVolFluctuations/phi_g{phi_global}/analysis/X{X:.3f}/mergers/{merged_compartments}/best_volume_slice/\"\n",
    "        input_filename = f\"best_slice.pkl\"\n",
    "        input_file = os.path.join(input_filepath, input_filename)\n",
    "        with gzip.open(input_file, 'rb') as f:\n",
    "            loaded_data = pickle.load(f)\n",
    "        best_slice = loaded_data[\"best_slice\"]\n",
    "        min_F_slice = loaded_data[\"min_F\"]\n",
    "\n",
    "        if min_F_slice < min_F_best:\n",
    "            min_F_best = min_F_slice\n",
    "            best_merger_slice = best_slice\n",
    "            best_merger_compartment = merged_compartments\n",
    "            \n",
    "    output_filepath = f\"../../../../../../../../media/vchirag24/Shared Drive/Chirag/3_comp_3_phase/data/withVolFluctuations/phi_g{phi_global}/analysis/X{X:.3f}/mergers/\"\n",
    "    output_filename = f\"best_merger.pkl\"\n",
    "    if not os.path.exists(output_filepath):\n",
    "        os.makedirs(output_filepath)\n",
    "    output_file = os.path.join(output_filepath, output_filename)\n",
    "    \n",
    "    data_to_save = {\n",
    "        \"best_merger_compartment\": best_merger_compartment,\n",
    "        \"best_merger_slice\": best_merger_slice,\n",
    "        \"metadata\": \"stores the slice in the best merged compartments which returns the lowest free energy possible\"\n",
    "        }\n",
    "    \n",
    "    with gzip.open(output_file, \"wb\") as f:\n",
    "        pickle.dump(data_to_save, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac5f5f2-857e-4e8b-9eac-df692e85d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting contours for the best slices and the best merger\n",
    "def plot_Contours(Xs):\n",
    "    for X in (Xs):\n",
    "        merged_compartments_list = [np.array([1, 2], dtype=np.int64), np.array([2, 3], dtype=np.int64), np.array([1, 3], dtype=np.int64)]\n",
    "        # merged_compartments_list = [np.array([1, 2], dtype=np.int64)]\n",
    "    \n",
    "        # Load the best merger\n",
    "        input_filepath = f\"../../../../../../../../media/vchirag24/Shared Drive/Chirag/3_comp_3_phase/data/withVolFluctuations/phi_g{phi_global}/analysis/X{X:.3f}/mergers/\"\n",
    "        input_filename = f\"best_merger.pkl\"\n",
    "        input_file = os.path.join(input_filepath, input_filename)\n",
    "        with gzip.open(input_file, \"rb\") as f:\n",
    "            loaded_data_best = pickle.load(f)\n",
    "            \n",
    "        # LOAD the best slice\n",
    "        for idx, merged_compartments in enumerate(merged_compartments_list):\n",
    "            # Get the best slice for each merger\n",
    "            input_filepath = f\"../../../../../../../../media/vchirag24/Shared Drive/Chirag/3_comp_3_phase/data/withVolFluctuations/phi_g{phi_global}/analysis/X{X:.3f}/mergers/{merged_compartments}/best_volume_slice/\"\n",
    "            input_filename = f\"best_slice.pkl\"\n",
    "            input_file = os.path.join(input_filepath, input_filename)\n",
    "            with gzip.open(input_file, 'rb') as f:\n",
    "                loaded_data = pickle.load(f)\n",
    "            best_slice = loaded_data[\"best_slice\"]\n",
    "    \n",
    "    \n",
    "            # Now, LOAD the phi data\n",
    "            input_filepath = f\"../../../../../../../../media/vchirag24/Shared Drive/Chirag/3_comp_3_phase/data/withVolFluctuations/phi_g{phi_global}/raw/X{X:.3f}/mergers/{merged_compartments}/volume_slices/\"\n",
    "            input_filename = f\"eta_m{best_slice:.3f}.pkl\"\n",
    "            input_file = os.path.join(input_filepath, input_filename)\n",
    "            \n",
    "            with gzip.open(input_file, \"rb\") as f:\n",
    "                loaded_data = pickle.load(f)\n",
    "            # print(loaded_data[\"metadata\"])\n",
    "    \n",
    "            # PLOT a contour for this loaded data\n",
    "            phi1_grid = np.linspace(min(loaded_data[\"phi_1merged\"]), max(loaded_data[\"phi_1merged\"]), 100)\n",
    "            phi2_grid = np.linspace(min(loaded_data[\"phi_2merged\"]), max(loaded_data[\"phi_2merged\"]), 100)\n",
    "            phi1_mesh, phi2_mesh = np.meshgrid(phi1_grid, phi2_grid)\n",
    "    \n",
    "            # Interpolate F values onto the grid\n",
    "            F_grid = griddata(\n",
    "                (loaded_data[\"phi_1merged\"], loaded_data[\"phi_2merged\"]), \n",
    "                loaded_data[\"F\"], \n",
    "                (phi1_mesh, phi2_mesh), \n",
    "                method='cubic'\n",
    "            )\n",
    "    \n",
    "            # Create the contour plot\n",
    "            fig, ax = plt.subplots(figsize=(4.25, 3))\n",
    "            contour = plt.contourf(phi1_mesh, phi2_mesh, F_grid, levels=1000, cmap = \"RdYlBu_r\")\n",
    "\n",
    "            cbar = plt.colorbar(contour, label=r'$\\mathbf{F\\, (k_BT)}$')\n",
    "    \n",
    "            # Bolden the label\n",
    "            cbar.set_label(r'$\\mathbf{F\\, (k_BT)}$', weight='bold', fontsize=10)\n",
    "            \n",
    "            # Bolden the tick numbers\n",
    "            cbar.ax.tick_params(\n",
    "                axis='y',          # Apply to y-axis (colorbar's axis)\n",
    "                direction='in',    # Ticks point inward\n",
    "                length=2,          # Tick length (adjust as needed)\n",
    "                width=0.5,         # Tick width (optional)\n",
    "                labelsize=8,      # Tick label size\n",
    "            )\n",
    "            for label in cbar.ax.get_yticklabels():\n",
    "                label.set_weight('bold')\n",
    "                    \n",
    "            # Mark the minimum value of F\n",
    "            min_F_index = np.argmin(loaded_data[\"F\"])\n",
    "            min_phi1 = loaded_data[\"phi_1merged\"][min_F_index]\n",
    "            min_phi2 = loaded_data[\"phi_2merged\"][min_F_index]\n",
    "            min_F = loaded_data[\"F\"][min_F_index]\n",
    "    \n",
    "            ax.scatter(\n",
    "                min_phi1, min_phi2, \n",
    "                color='lime', \n",
    "                s=10,\n",
    "                marker = \"*\",\n",
    "                linewidth=0.5,\n",
    "                # label=label\n",
    "            )\n",
    "            \n",
    "            \n",
    "            # Add contour lines\n",
    "            CS = plt.contour(phi1_mesh, phi2_mesh, F_grid, levels=40, colors='k', linewidths=0.25)\n",
    "            \n",
    "            phi1_d = phi1_grid[1]-phi1_grid[0]\n",
    "            phi2_d = phi2_grid[1]-phi2_grid[0]\n",
    "            ax.set_xlim([phi1_grid[0]-2*phi1_d, phi1_grid[-1]+2*phi1_d])\n",
    "            ax.set_ylim([phi2_grid[0]-2*phi2_d, phi2_grid[-1]+2*phi2_d])\n",
    "            \n",
    "            \n",
    "            ax.set_xlabel(r'$\\mathbf{\\phi_{1, {merged}}}$', fontsize=12)\n",
    "            ax.set_ylabel(r'$\\mathbf{\\phi_{2, {merged}}}$', fontsize=12)\n",
    "            ax.tick_params(axis='both', which='both', direction='in', width=1.5, length=3.5, labelsize=10)\n",
    "            ax.tick_params(axis='both', which='minor', direction='in', width=0.5, length=2, labelsize=8)\n",
    "            for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "                label.set_fontweight(\"bold\")\n",
    "\n",
    "            # title = f\"X = {X:.3f}\" + \"\\n\" + r\"$\\Phi^{\\text{global}}=$\" + f\"{phi_global}\" +\"\\n\" + f'Merged compartments: {loaded_data[\"metadata\"][\"merged_compartments\"]}' + \"\\n\" + r\"$\\eta^{\\text{merged}}=$\" + f\"{best_slice:.3f}\"\n",
    "            # plt.title(title)\n",
    "    \n",
    "            \n",
    "            # phi1_guess = loaded_data[\"metadata\"][\"initial_merged_concentration_guess\"][0]\n",
    "            # phi2_guess = loaded_data[\"metadata\"][\"initial_merged_concentration_guess\"][1]\n",
    "            # suptitle = r\"($\\phi_{1, \\text{merged}}^{in}, \\phi_{2, \\text{merged}}^{in}) =$\" + f\"({phi1_guess:.3f}, {phi2_guess:.3f})\"\n",
    "            # fig.suptitle(suptitle)\n",
    "            \n",
    "            # plt.legend(loc = \"upper right\")\n",
    "            # legend = ax.legend(loc='upper center', fontsize=6, frameon=True)\n",
    "            # for text in legend.get_texts():\n",
    "            #     text.set_fontweight(\"bold\") \n",
    "\n",
    "            # title = r\"($\\mathbf{\\phi_{1, {merged}}^{{best}}, \\phi_{2, {merged}}^{{best}}}) \\mathbf{=}$\" + f\"({min_phi1:.3f}, {min_phi2:.3f}, {best_slice:.3f})\" + \"\\n\" + r\"$\\mathbf{\\eta_{merged}^{{best}}}$\"\n",
    "            # fig.suptitle(title, fontweight=\"bold\")\n",
    "            \n",
    "            fig.tight_layout()            \n",
    "            input_filepath = f\"../../../../../../../../media/vchirag24/Shared Drive/Chirag/3_comp_3_phase/data/withVolFluctuations/phi_g{phi_global}/raw/X{X:.3f}/mergers/{merged_compartments}/volume_slices/\"\n",
    "            input_filename = f\"eta_m{best_slice:.3f}.pkl\"\n",
    "            input_file = os.path.join(input_filepath, input_filename)\n",
    "            \n",
    "            with gzip.open(input_file, \"rb\") as f:\n",
    "                loaded_data = pickle.load(f)\n",
    "            # print(best_slice)\n",
    "            output_filepath = f\"../../../../../../../../media/vchirag24/Shared Drive/Chirag/3_comp_3_phase/data/withVolFluctuations/phi_g{phi_global}/analysis/X{X:.3f}/mergers/{merged_compartments}/best_volume_slice/\"\n",
    "            output_filename = f\"({min_phi1:.3f}, {min_phi2:.3f}, {best_slice:.3f}).png\"\n",
    "            if not os.path.exists(output_filepath):\n",
    "                os.makedirs(output_filepath)\n",
    "            output_file = os.path.join(output_filepath, output_filename)\n",
    "            \n",
    "            plt.savefig(output_file, dpi=400)\n",
    "            # plt.close()\n",
    "    \n",
    "            if np.array_equal(merged_compartments, loaded_data_best[\"best_merger_compartment\"]):\n",
    "                output_filepath = f\"../../../../../../../../media/vchirag24/Shared Drive/Chirag/3_comp_3_phase/data/withVolFluctuations/phi_g{phi_global}/analysis/X{X:.3f}/mergers/\"\n",
    "                output_filename = f\"({min_phi1:.3f}, {min_phi2:.3f}, {best_slice:.3f})_best.png\"\n",
    "                if not os.path.exists(output_filepath):\n",
    "                    os.makedirs(output_filepath)\n",
    "                output_file = os.path.join(output_filepath, output_filename)\n",
    "                \n",
    "                plt.savefig(output_file, dpi=400)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81ae858e-ddbe-41c1-9c85-bcd6a9dceeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 1000 ticks ([-0.050850000000000006, ..., 0.099]), which exceeds Locator.MAXTICKS (1000).\n",
      "Locator attempting to generate 1003 ticks ([-0.023100000000000002, ..., 0.2775]), which exceeds Locator.MAXTICKS (1000).\n",
      "Locator attempting to generate 1001 ticks ([-0.022000000000000002, ..., 0.378]), which exceeds Locator.MAXTICKS (1000).\n",
      "Locator attempting to generate 1002 ticks ([0.4905, ..., 0.9910000000000001]), which exceeds Locator.MAXTICKS (1000).\n",
      "Locator attempting to generate 1000 ticks ([-0.021, ..., 0.978]), which exceeds Locator.MAXTICKS (1000).\n",
      "Locator attempting to generate 1000 ticks ([-0.0216, ..., 0.5778000000000001]), which exceeds Locator.MAXTICKS (1000).\n",
      "Locator attempting to generate 1000 ticks ([0.6162000000000001, ..., 1.2156000000000002]), which exceeds Locator.MAXTICKS (1000).\n",
      "Locator attempting to generate 1000 ticks ([0.6240000000000001, ..., 1.2234000000000003]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    }
   ],
   "source": [
    "plot_Contours(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476edf5-1941-4e03-937a-a1a343b4886e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
